{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ffdcf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import spacy\n",
    "import numpy as np\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe('sentencizer')\n",
    "from tqdm.notebook import tqdm \n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from adjustText import adjust_text\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.phrases.Phraser(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca71e283",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/benbadnani/Desktop/Spring 2022/BU Spark/TBG_unique_raw.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/73/tczzn7854g585r2p_1tbs9340000gn/T/ipykernel_2413/3677173129.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m df = dd.read_csv('TBG_unique_raw.csv', \n\u001b[0m\u001b[1;32m      2\u001b[0m                  \u001b[0musecols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'position_section'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'hl1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hl2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lede'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                  dtype = {'position_section': str,'hl1': object, \n\u001b[1;32m      4\u001b[0m                           'hl2': object, 'lede': str, 'body': str})\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_partitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/dask/dataframe/io/csv.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(urlpath, blocksize, lineterminator, compression, sample, sample_rows, enforce, assume_missing, storage_options, include_path_column, **kwargs)\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m     ):\n\u001b[0;32m--> 746\u001b[0;31m         return read_pandas(\n\u001b[0m\u001b[1;32m    747\u001b[0m             \u001b[0mreader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0murlpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/dask/dataframe/io/csv.py\u001b[0m in \u001b[0;36mread_pandas\u001b[0;34m(reader, urlpath, blocksize, lineterminator, compression, sample, sample_rows, enforce, assume_missing, storage_options, include_path_column, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblocksize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0mb_lineterminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlineterminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m     b_out = read_bytes(\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0murlpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_lineterminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/dask/bytes/core.py\u001b[0m in \u001b[0;36mread_bytes\u001b[0;34m(urlpath, delimiter, not_zero, blocksize, sample, compression, include_path, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m                     \u001b[0;34m\"To read, set blocksize=None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 )\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                 raise ValueError(\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/fsspec/implementations/local.py\u001b[0m in \u001b[0;36minfo\u001b[0;34m(self, path, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;31m# str or path-like\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strip_protocol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mlink\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mS_ISLNK\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlink\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/benbadnani/Desktop/Spring 2022/BU Spark/TBG_unique_raw.csv'"
     ]
    }
   ],
   "source": [
    "df = dd.read_csv('TBG_unique_raw.csv', \n",
    "                 usecols = ['position_section','hl1', 'hl2', 'lede', 'body'], \n",
    "                 dtype = {'position_section': str,'hl1': object, \n",
    "                          'hl2': object, 'lede': str, 'body': str})\n",
    "df = df.map_partitions(lambda x: x.fillna(''))\n",
    "df['content'] = df.map_partitions(lambda x: x[['hl1', 'hl2', 'lede', 'body']].agg(' '.join, axis=1))\n",
    "df = df.drop(columns = ['hl1', 'hl2', 'lede', 'body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "36642bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_preprocess(corpus_iterable):\n",
    "    global id2word\n",
    "    pre_processed_corpus = []\n",
    "    temp = []\n",
    "    for x in tqdm(nlp.pipe(corpus_iterable), total = len(corpus_iterable)):\n",
    "        for y in x.sents: \n",
    "            temp.append('<s>')\n",
    "            for z in y: \n",
    "                if z.is_word and not z.is_stop:\n",
    "                    temp.append(z.lemma_.lower())\n",
    "            temp.append('</s>')\n",
    "        pre_processed_corpus.append(temp)\n",
    "        temp = []\n",
    "        \n",
    "    id2word.add_documents(pre_processed_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3901c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = Dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "00bd259a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c8da84bb83400fa85e0a725a48af9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arr = df.content.values\n",
    "with nlp.select_pipes(disable=['tok2vec', 'parser', 'ner']):\n",
    "    pre_processed_corpus = arr.map_blocks(lambda x: custom_preprocess(x), \n",
    "                                          new_axis = 0, dtype = object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc563bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_corpus.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9ca692",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word.filter_extremes(no_below=15, no_above=0.4, keep_n=80000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c0afee",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LdaModel(id2word=id2word, \n",
    "                     num_topics=7, alpha='auto', eval_every=5, per_word_topics=True, chunksize = 100, passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "35d0047c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> unknown </td>\n",
       "                        <td> unknown </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1, nan) </td>\n",
       "                        <td> (1, nan) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 1928 Tasks </td>\n",
       "                        <td> 241 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> object </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        \n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<lambda, shape=(1, nan), dtype=object, chunksize=(1, nan), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_processed_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1852cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "\n",
    "def plot_figure(reduced_matrix, name): \n",
    "    fig, ax = plt.subplots()\n",
    "    plt.scatter(reduced_matrix[:,0], reduced_matrix[:,1])\n",
    "    texts =\\\n",
    "    [plt.text(reduced_matrix[i, 0], reduced_matrix[i, 1], \n",
    "              word, ha='center', va='center') for i, word in enumerate(plays)]\n",
    "    adjust_text(texts, arrowprops=dict(arrowstyle='->', color='red'))\n",
    "    plt.savefig(f'{name}.pdf')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
